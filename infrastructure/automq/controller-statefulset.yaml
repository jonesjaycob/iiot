---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: automq-controller
  namespace: industrial-iot
  labels:
    app: automq
    component: controller
spec:
  serviceName: automq-controller-headless
  replicas: 1
  selector:
    matchLabels:
      app: automq
      component: controller
  template:
    metadata:
      labels:
        app: automq
        component: controller
    spec:
      containers:
        - name: automq-controller
          image: automqinc/automq:latest
          ports:
            - containerPort: 9093
              name: controller
          env:
            - name: KAFKA_S3_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: rootUser
            - name: KAFKA_S3_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: rootPassword
            - name: KAFKA_HEAP_OPTS
              value: "-Xms256m -Xmx512m"
          command:
            - /bin/bash
            - -c
            - |
              CLUSTER_ID="iiot-automq-clust"
              S3_URL="0@s3://automq-data?region=us-east-1&endpoint=http://minio.industrial-iot.svc.cluster.local:9000&pathStyle=true&authType=static&accessKey=${KAFKA_S3_ACCESS_KEY}&secretKey=${KAFKA_S3_SECRET_KEY}"

              cat > /tmp/controller.properties <<'PROPEOF'
              process.roles=controller
              node.id=0
              controller.quorum.bootstrap.servers=automq-controller-0.automq-controller-headless.industrial-iot.svc.cluster.local:9093
              listeners=CONTROLLER://:9093
              controller.listener.names=CONTROLLER
              log.dirs=/var/lib/kafka/data/kraft-controller-logs
              offsets.topic.replication.factor=1
              transaction.state.log.replication.factor=1
              transaction.state.log.min.isr=1
              num.partitions=3
              elasticstream.enable=true
              PROPEOF
              echo "s3.data.buckets=${S3_URL}" >> /tmp/controller.properties
              echo "s3.ops.buckets=${S3_URL}" >> /tmp/controller.properties
              # Strip leading whitespace from properties
              sed -i 's/^[[:space:]]*//' /tmp/controller.properties

              # Clear old data and reformat
              rm -rf /var/lib/kafka/data/kraft-controller-logs
              echo "Formatting KRaft storage..."
              /opt/kafka/kafka/bin/kafka-storage.sh format \
                --config /tmp/controller.properties \
                --cluster-id "${CLUSTER_ID}" \
                --standalone \
                --ignore-formatted

              echo "Starting AutoMQ controller..."
              exec /opt/kafka/kafka/bin/kafka-server-start.sh /tmp/controller.properties
          resources:
            requests:
              memory: 512Mi
              cpu: 250m
            limits:
              memory: 1Gi
              cpu: 500m
          volumeMounts:
            - name: data
              mountPath: /var/lib/kafka/data
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: hostpath
        resources:
          requests:
            storage: 5Gi
